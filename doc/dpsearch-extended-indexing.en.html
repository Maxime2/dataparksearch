<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Extended indexing features</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REL="HOME"
TITLE="DataparkSearch Engine 4.54"
HREF="index.en.html"><LINK
REL="UP"
TITLE="Indexing"
HREF="dpsearch-indexing.en.html"><LINK
REL="PREVIOUS"
TITLE="Other commands are used in indexer.conf"
HREF="dpsearch-indexcmd.en.html"><LINK
REL="NEXT"
TITLE="Using syslog"
HREF="dpsearch-syslog.en.html"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="datapark.css"><META
NAME="Description"
CONTENT="DataparkSearch - Full Featured Web site Open Source Search Engine Software over the Internet and Intranet Web Sites Based on SQL Database. It is a Free search software covered by GNU license."><META
NAME="Keywords"
CONTENT="shareware, freeware, download, internet, unix, utilities, search engine, text retrieval, knowledge retrieval, text search, information retrieval, database search, mining, intranet, webserver, index, spider, filesearch, meta, free, open source, full-text, udmsearch, website, find, opensource, search, searching, software, udmsearch, engine, indexing, system, web, ftp, http, cgi, php, SQL, MySQL, database, php3, FreeBSD, Linux, Unix, DataparkSearch, MacOS X, Mac OS X, Windows, 2000, NT, 95, 98, GNU, GPL, url, grabbing"></HEAD
><BODY
CLASS="SECT1"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000C4"
VLINK="#1200B2"
ALINK="#C40000"
><!--#include virtual="body-before.html"--><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="3"
ALIGN="center"
>DataparkSearch Engine 4.54: Reference manual</TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="bottom"
><A
HREF="dpsearch-indexcmd.en.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="80%"
ALIGN="center"
VALIGN="bottom"
>Chapter 3. Indexing</TD
><TD
WIDTH="10%"
ALIGN="right"
VALIGN="bottom"
><A
HREF="dpsearch-syslog.en.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="EXTENDED-INDEXING"
>3.11. Extended indexing features</A
></H1
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="NEWS"
>3.11.1. News extensions
<A
NAME="AEN2666"
></A
></A
></H2
><P
>To enable News extensions do these steps:

<P
></P
><UL
><LI
><P
>Build <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> with <TT
CLASS="LITERAL"
>news://</TT
> scheme support,
i.e. do not disbale it when run configure (News extensions are enabled by default)</P
></LI
><LI
><P
><A
NAME="AEN2676"
></A
>
Add the command <B
CLASS="COMMAND"
>NewsExtensions yes</B
> into your <TT
CLASS="FILENAME"
>indexer.conf</TT
> configuration file.
Also add these <B
CLASS="COMMAND"
>Section</B
> commands into <TT
CLASS="FILENAME"
>sections.conf</TT
> file:
<PRE
CLASS="PROGRAMLISTING"
>Section Header.References 18 0
Section Header.Message-ID 19 0
Section Header.Parent-ID  20 0</PRE
>
You can also use <TT
CLASS="LITERAL"
>Header.Subject</TT
> or <TT
CLASS="LITERAL"
>Header.From</TT
>.
Please remember, you need to specify non-zero maximal length for any of these sections if you need to store it into <TT
CLASS="LITERAL"
>urlinfo</TT
> table and/or use it in your search template.</P
></LI
></UL
></P
><P
>With News extensions enable, the <B
CLASS="COMMAND"
>indexer</B
> try to detect Parent-ID for each article indexed and 
also put the pairs (<TT
CLASS="LITERAL"
>Parent-ID</TT
>, <TT
CLASS="LITERAL"
>ID</TT
>) into <TT
CLASS="LITERAL"
>links</TT
> table.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="HTDB"
>3.11.2. Indexing SQL database tables (htdb: virtual URL scheme)</A
></H2
><A
NAME="AEN2694"
></A
><P
><SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> can index SQL database text fields - the 
so called  htdb: virtual URL scheme.</P
><P
>Using htdb:/ virtual scheme you can build full text
index of your SQL tables as well as index your database driven WWW
server.</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>You must have PRIMARY key on the table you want to index.</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="HTDB-INDEXER"
>3.11.2.1. HTDB indexer.conf commands</A
></H3
><P
>Five <TT
CLASS="FILENAME"
>indexer.conf</TT
> commands provide HTDB. They are 
<B
CLASS="COMMAND"
>HTDBAddr</B
>, <B
CLASS="COMMAND"
>HTDBList</B
>, <B
CLASS="COMMAND"
>HTDBLimit</B
>, <B
CLASS="COMMAND"
>HTDBDoc</B
> and
<B
CLASS="COMMAND"
>HTDBText</B
>. </P
><P
><A
NAME="AEN2712"
></A
>
			<B
CLASS="COMMAND"
>HTDBAddr</B
> is used to specify database connection. 
It's syntax identical to <B
CLASS="COMMAND"
>DBAddr</B
> command.</P
><P
><A
NAME="AEN2718"
></A
>
			<B
CLASS="COMMAND"
>HTDBList</B
> is SQL query to
generate list of all URLs which correspond to records in the table
using PRIMARY key field. You may use either absolute or relative URLs
in HTDBList command:</P
><P
>For example:
		<PRE
CLASS="PROGRAMLISTING"
>HTDBList "SELECT concat('htdb:/',id) FROM messages"
    or
HTDBList "SELECT id FROM messages"</PRE
></P
><P
><A
NAME="AEN2725"
></A
>
<B
CLASS="COMMAND"
>HTDBLimit</B
> command may be used to specify maximal number of records in one SELECT operation.
It allow reduce memory usage for big data tables indexing. For example:
<PRE
CLASS="PROGRAMLISTING"
>HTDBLimit 512</PRE
></P
><P
><A
NAME="AEN2731"
></A
>
			<B
CLASS="COMMAND"
>HTDBDoc</B
> is a query to get only certain record from database using PRIMARY key value.</P
><P
>HTDBList SQL query is used for all URLs which
end with '/' sign. For other URLs SQL query given in HTDBDoc is
used.</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>HTDBDoc query must return FULL HTTP
response with headers. So, you can build very flexible indexing system
giving different HTTP status in query. Take a look at HTTP response
codes section of documentation to understand indexer behavior when it
gets different HTTP status.</P
></BLOCKQUOTE
></DIV
><P
>If there is no result of HTDBDoc or query does
return several records, HTDB retrieval system generates "HTTP 404 Not
Found". This may happen at reindex time if record was deleted from
your table since last reindexing. You may use <B
CLASS="COMMAND"
>HoldBadHrefs 0</B
> to
delete such records from <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> tables as well.</P
><P
>You may use several HTDBDoc/List commands in one
<TT
CLASS="FILENAME"
>indexer.conf</TT
> with corresponding Server
commands.</P
><P
><A
NAME="AEN2744"
></A
>
<B
CLASS="COMMAND"
>HTDBText &lt;section&gt;</B
> is a query to get raw text data from database using PRIMARY key value 
collected via <B
CLASS="COMMAND"
>HTDBList</B
> command.
The &lt;section&gt; parameter is specify the section name useing for storing this data. This query may return as many rows as required.
You may specify several <B
CLASS="COMMAND"
>HTDBText</B
> commands per <B
CLASS="COMMAND"
>Server</B
> or <B
CLASS="COMMAND"
>Realm</B
> command.
		<PRE
CLASS="PROGRAMLISTING"
>DBAddr mysql://foo:bar@localhost/database/?dbmode=single

HTDBAddr mysql://foofoo:barbar@localhost/database/

HTDBList "SELECT DISTINCT topic_id FROM messages"

HTDBText body "SELECT raw_text\
FROM messages WHERE topic_id='$1'"

Server htdb:/</PRE
></P
><P
>It' possible to specify both <B
CLASS="COMMAND"
>HTDBDoc</B
> and <B
CLASS="COMMAND"
>HTDBText</B
> commands per one <B
CLASS="COMMAND"
>Server</B
>
or <B
CLASS="COMMAND"
>Realm</B
> command. <B
CLASS="COMMAND"
>HTDBText</B
> commands are processing first.</P
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="HTDB-VAR"
>3.11.2.2. HTDB variables</A
></H3
><A
NAME="AEN2761"
></A
><P
>You may use PATH parts of URL as parameters of
both HTDBList and HTDBDoc SQL queries. All parts are to be used as $1,
$2,  ... $n, where number is the number of PATH part:

		<PRE
CLASS="PROGRAMLISTING"
>htdb:/part1/part2/part3/part4/part5
         $1    $2    $3    $4    $5</PRE
></P
><P
>For example, you have this <TT
CLASS="FILENAME"
>indexer.conf</TT
> command:
		<PRE
CLASS="PROGRAMLISTING"
>HTDBList "SELECT id FROM catalog WHERE category='$1'"</PRE
>
		</P
><P
>When htdb:/cars/  URL is indexed, $1 will be replaced with 'cars':
		<PRE
CLASS="PROGRAMLISTING"
>SELECT id FROM catalog WHERE category='cars'</PRE
>
		</P
><P
>You may use long URLs to provide several
parameters to both HTDBList and HTDBDoc queries. For example,
<TT
CLASS="LITERAL"
>htdb:/path1/path2/path3/path4/id</TT
> with query:
		<PRE
CLASS="PROGRAMLISTING"
>HTDBList "SELECT id FROM table WHERE field1='$1' AND field2='$2' and field3='$3'"</PRE
>
		</P
><P
>This query will generate the following URLs:
		<PRE
CLASS="PROGRAMLISTING"
>htdb:/path1/path2/path3/path4/id1
...
htdb:/path1/path2/path3/path4/idN</PRE
></P
><P
>for all values of the field "id" which are in HTDBList output.</P
><P
>It's possible to specify a regex-based pattern to match the URL into HTDB variables for <B
CLASS="COMMAND"
>HTDBDoc</B
> and 
<B
CLASS="COMMAND"
>HTDBtext</B
> commands:
<PRE
CLASS="PROGRAMLISTING"
>HTDBText header "SELECT header FROM news WHERE section=$1 AND article=$2" "^/section/([0-9]+)/art/([0-9]+)\.html"</PRE
>
		</P
><P
>		in this case the regex pattern specified is matched against the full path and filename of the URL.
		</P
><P
>For the <B
CLASS="COMMAND"
>HTDBText</B
> command it is possible to use search template meta-variables (as for example, $(DP_ID), $(URL), etc.) to form a sql-query. E.g.:
<PRE
CLASS="PROGRAMLISTING"
>HTDBText hint "SELECT hint FROM hints WHERE url = '$(url)'"</PRE
>
		</P
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="HTDB-FULLTEXT"
>3.11.2.3. Creating full text index</A
></H3
><P
>Using htdb:/ scheme you can create full text
index and use it further in your application. Lets imagine you have a
big SQL table which stores for example web board messages in plain
text format. You also want to build an application with messages
search facility. Lets say messages are stored in "messages" table with
two fields "id" and "msg". "id" is an integer primary key and "msg"
big text field contains messages themselves. Using usual SQL LIKE
search may take long time to answer:
		<PRE
CLASS="PROGRAMLISTING"
>SELECT id, message FROM message WHERE message LIKE '%someword%'</PRE
>
		</P
><P
>Using <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> htdb: scheme you have a
possibility to create full text index on "message" table. Install
<SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> in usual order. Then edit your
<TT
CLASS="FILENAME"
>indexer.conf</TT
>:
		<PRE
CLASS="PROGRAMLISTING"
>DBAddr mysql://foo:bar@localhost/search/?dbmode=single

HTDBAddr mysql://foofoo:barbar@localhost/database/

HTDBList "SELECT id FROM messages"

HTDBDoc "SELECT concat(\
'HTTP/1.0 200 OK\\r\\n',\
'Content-type: text/plain\\r\\n',\
'\\r\\n',\
msg) \
FROM messages WHERE id='$1'"

Server htdb:/</PRE
>
		</P
><P
>After start indexer will insert 'htdb:/' URL
into database and will run an SQL query given in HTDBList. It will
produce 1,2,3, ..., N values in result. Those values will be
considered as links relative to 'htdb:/' URL. A list of new URLs in
the form htdb:/1, htdb:/2, ... , htdb:/N will be added into
database. Then HTDBDoc SQL query will be executed for each new
URL. HTDBDoc will produce HTTP document for each document in the
form:
		<PRE
CLASS="PROGRAMLISTING"
>HTTP/1.0 200 OK
Content-Type: text/plain

&lt;some text from 'message' field here&gt;</PRE
>
		</P
><P
>This document will be used to create full text
index using words from 'message' fields. Words will be stored in
'dict' table assuming that we are using 'single' storage mode.</P
><P
>After indexing you can use <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> tables to perform search:
		<PRE
CLASS="PROGRAMLISTING"
>SELECT url.url 
FROM url,dict 
WHERE dict.url_id=url.rec_id 
AND dict.word='someword';</PRE
>
		</P
><P
>As far as <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> 'dict' table has an index
on 'word' field this query will be executed much faster than queries
which use SQL LIKE search on 'messages' table.</P
><P
>You can also use several words in search:
		<PRE
CLASS="PROGRAMLISTING"
>SELECT url.url, count(*) as c 
FROM url,dict
WHERE dict.url_id=url.rec_id 
AND dict.word IN ('some','word')
GROUP BY url.url
ORDER BY c DESC;</PRE
>
		</P
><P
>Both queries will return 'htdb:/XXX' values in
url.url field. Then your application has to cat leading 'htdb:/' from
those values to get PRIMARY key values of your 'messages'
table.</P
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="HTDB-WEB"
>3.11.2.4. Indexing SQL database driven web server</A
></H3
><P
>You can also use htdb:/ scheme to index your
database driven WWW server. It allows to create indexes without having
to invoke your web server while indexing. So, it is much faster and
requires less CPU resources when direct indexing from WWW
server. </P
><P
>The main idea of indexing database driven web
server is to build full text index in usual order. The only thing is
that search must produce real URLs instead of URLs in 'htdb:/...'
form. This can be achieved using <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> aliasing tools.</P
><P
>HTDBList command generates URLs in the form:
		<PRE
CLASS="PROGRAMLISTING"
>http://search.site.ext/board/message.php?id=XXX</PRE
>
		</P
><P
>where XXX is a "messages" table primary key values.</P
><P
>For each primary key value HTDBDoc command generates text/html document with HTTP headers and content like this:
		<PRE
CLASS="PROGRAMLISTING"
>&lt;HTML&gt;
&lt;HEAD&gt;
&lt;TITLE&gt; ... subject field here .... &lt;/TITLE&gt;
&lt;META NAME="Description" Content=" ... author here ..."&gt;
&lt;/HEAD&gt;
&lt;BODY&gt; ... message text here ... &lt;/BODY&gt;</PRE
></P
><P
>At the end of <TT
CLASS="FILENAME"
>doc/samples/htdb.conf</TT
> we wrote three commands:
		<PRE
CLASS="PROGRAMLISTING"
>Server htdb:/
Realm  http://search.site.ext/board/message.php?id=*
Alias  http://search.site.ext/board/message.php?id=  htdb:/</PRE
>
		</P
><P
>First command says indexer to execute HTDBList query which will generate a list of messages in the form:
		<PRE
CLASS="PROGRAMLISTING"
>http://search.site.ext/board/message.php?id=XXX</PRE
>
		</P
><P
>Second command allow indexer to accept such message URLs using string match with '*' wildcard at the end.</P
><P
>Third command replaces
"http://search.site.ext/board/message.php?id=" substring in URL with
"htdb:/" when indexer retrieve documents with messages. It means that
"http://mysearch.udm.net/board/message.php?id=xxx" URLs will be shown
in search result, but "htdb:/xxx" URL will be indexed instead, where
xxx is the PRIMARY key value, the ID of record in "messages"
table.</P
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="EXEC"
>3.11.3. Indexing binaries output (exec: and cgi: virtual URL schemes)</A
></H2
><A
NAME="AEN2824"
></A
><P
><SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> supports exec: and cgi: virtual URL
schemes. They allows running an external program. This program must
return a result to it's stdout. Result must be in HTTP standard,
i.e. HTTP response header followed by document's content.</P
><P
>For example, when indexing both
<TT
CLASS="LITERAL"
>cgi:/usr/local/bin/myprog</TT
> and
<TT
CLASS="LITERAL"
>exec:/usr/local/bin/myprog</TT
>, indexer will execute
the <TT
CLASS="FILENAME"
>/usr/local/bin/myprog</TT
> program.</P
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXEC-CGI"
>3.11.3.1. Passing parameters to cgi: virtual scheme</A
></H3
><P
>When executing a program given in cgi: virtual
scheme, indexer emulates that program is running under HTTP server. It
creates REQUEST_METHOD environment variable with "GET" value and
QUERY_STRING variable according to HTTP standards. For example, if
<TT
CLASS="LITERAL"
>cgi:/usr/local/apache/cgi-bin/test-cgi?a=b&amp;d=e</TT
>
is being indexed, indexer creates QUERY_STRING with
<TT
CLASS="LITERAL"
>a=b&amp;d=e</TT
> value.  cgi: virtual URL scheme allows
indexing your site without having to invoke web servers even if you
want to index CGI scripts. For example, you have a web site with
static documents under <TT
CLASS="FILENAME"
>/usr/local/apache/htdocs/</TT
>
and with CGI scripts under
<TT
CLASS="FILENAME"
>/usr/local/apache/cgi-bin/</TT
>. Use the following
configuration:
		<PRE
CLASS="PROGRAMLISTING"
>Server http://localhost/
Alias  http://localhost/cgi-bin/	cgi:/usr/local/apache/cgi-bin/
Alias  http://localhost/		file:/usr/local/apache/htdocs/</PRE
>
		</P
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXEC-EXEC"
>3.11.3.2. Passing parameters to exec: virtual scheme</A
></H3
><P
>indexer does not create QUERY_STRING variable
like in cgi: scheme. It creates a command line with argument given in
URL after ? sign. For example, when indexing
<TT
CLASS="LITERAL"
>exec:/usr/local/bin/myprog?a=b&amp;d=e</TT
>, this
command will be executed:
		<PRE
CLASS="PROGRAMLISTING"
>/usr/local/bin/myprog "a=b&amp;d=e" </PRE
>
		</P
></DIV
><DIV
CLASS="SECT3"
><H3
CLASS="SECT3"
><A
NAME="EXEC-EXT"
>3.11.3.3. Using exec: virtual scheme as an external retrieval system</A
></H3
><P
>exec: virtual scheme allow using it as an
external retrieval system. It allows using protocols which are not
supported natively by <SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
>. For example, you can use curl
program which is available from <A
HREF="http://curl.haxx.se/"
TARGET="_top"
>http://curl.haxx.se/</A
> to index HTTPS sites.</P
><P
>Put this short script to
<TT
CLASS="LITERAL"
>/usr/local/dpsearch/bin/</TT
> under
<TT
CLASS="FILENAME"
>curl.sh</TT
> name.
		<PRE
CLASS="PROGRAMLISTING"
>#!/bin/sh
/usr/local/bin/curl -i $1 2&#62;/dev/null</PRE
></P
><P
>This script takes an URL given in command line
argument and executes curl program to download it.  -i argument says
curl to output result together with HTTP headers.</P
><P
>Now use these commands in your <TT
CLASS="FILENAME"
>indexer.conf</TT
>:
		<PRE
CLASS="PROGRAMLISTING"
>Server https://some.https.site/
Alias  https://  exec:/usr/local/dpsearch/etc/curl.sh?https://</PRE
>
		</P
><P
>When indexing
<TT
CLASS="FILENAME"
>https://some.https.site/path/to/page.html</TT
>,
indexer will translate this URL to 
		<PRE
CLASS="PROGRAMLISTING"
>exec:/usr/local/dpsearch/etc/curl.sh?https://some.https.site/path/to/page.html</PRE
>
		</P
><P
>execute the <TT
CLASS="FILENAME"
>curl.sh</TT
> script:
		<PRE
CLASS="PROGRAMLISTING"
>/usr/local/dpsearch/etc/curl.sh "https://some.https.site/path/to/page.html"</PRE
>
		</P
><P
>and take it's output.</P
></DIV
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="MIRROR"
>3.11.4. Mirroring</A
></H2
><A
NAME="AEN2867"
></A
><P
><A
NAME="AEN2870"
></A
>
You may specify a path to root dir to enable sites mirroring
	<PRE
CLASS="PROGRAMLISTING"
>MirrorRoot /path/to/mirror</PRE
>
	</P
><P
><A
NAME="AEN2875"
></A
>
You may specify as well root directory of mirrored document's headers indexer will store HTTP headers to local disk too.
	<PRE
CLASS="PROGRAMLISTING"
>MirrorHeadersRoot /path/to/headers</PRE
>
	</P
><P
><A
NAME="AEN2880"
></A
>
You may specify period during which earlier mirrored files will be used while indexing instead of real downloading.
	<PRE
CLASS="PROGRAMLISTING"
>MirrorPeriod &lt;time&gt;</PRE
>
	</P
><P
>It is very useful when you do some experiments with
<SPAN
CLASS="APPLICATION"
>DataparkSearch</SPAN
> indexing the same hosts and do not want much traffic
from/to Internet. If MirrorHeadersRoot is not specified and headers
are not stored to local disk then default Content-Type's given in
AddType commands will be used. Default value of the MirrorPeriod is
-1, which means <TT
CLASS="LITERAL"
>do not use mirrored files</TT
>.</P
><P
>&lt;time&gt; is in the form
<TT
CLASS="LITERAL"
>xxxA[yyyB[zzzC]]</TT
> (Spaces are allowed between xxx
and A and yyy and so on) where xxx, yyy, zzz are numbers (can be
negative!). A, B, C can be one of the following:
	<PRE
CLASS="PROGRAMLISTING"
>		s - second
		M - minute
		h - hour
		d - day
		m - month
		y - year</PRE
></P
><P
>(these letters are the same as in strptime/strftime functions)</P
><P
>Examples:
	<PRE
CLASS="PROGRAMLISTING"
>15s - 15 seconds
4h30M - 4 hours and 30 minutes
1y6m-15d - 1 year and six month minus 15 days
1h-10M+1s - 1 hour minus 10 minutes plus 1 second</PRE
></P
><P
>If you specify only number without any character, it is
assumed that time is given in seconds (this behavior is for
compatibility with versions prior to 3.1.7).</P
><P
>The following command will force using local copies for one day:
	<PRE
CLASS="PROGRAMLISTING"
>MirrorPeriod 1d</PRE
>
	</P
><P
>If your pages are already indexed, when you re-index
with -a indexer will check the headers and only download files that
have been modified since the last indexing. Thus, all pages that are
not modified will not be downloaded and therefore not mirrored
either. To create the mirror you need to either (a) start again with a
clean database or (b) use the -m switch. </P
><P
>You can actually use the created files as a full
featured mirror to you site. However be careful: indexer will not
download a document that is larger than MaxDocSize. If a document is
larger it will be only partially downloaded. If you site has no large
documents, everything will be fine.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="DATA-ACQ"
>3.11.5. Data acquisition</A
></H2
><A
NAME="AEN2900"
></A
><A
NAME="AEN2902"
></A
><P
>With <B
CLASS="COMMAND"
>ActionSQL</B
> command you can execute SQL-queries with document related data while indexing.
The syntax of <B
CLASS="COMMAND"
>ActionSQL</B
> command is as follow:
<PRE
CLASS="PROGRAMLISTING"
>ActionSQL [add | update | delete] &lt;section&gt; &lt;pattern&gt; &lt;sql-template&gt; [&lt;dbaddr&gt;]</PRE
>
where &lt;section&gt; is the name of document section to check for regex pattern &gt;pattern&gt; match. If a match is found then the &lt;sql-template&gt; is filled with regex meta-variables $1-$9 as well with search template meta-variables (as for example, $(Title), $(Last-Modified), etc.) to form a sql-query, which is executed in the first DBAddr defined in indexer.conf file. If the optional &lt;dbaddr&gt; paramater of ActionSQL command is set, a new connection is set according this DBAddr and sql-query is executed in this connection.</P
><P
>One of options <CODE
CLASS="OPTION"
>add</CODE
>, <CODE
CLASS="OPTION"
>update</CODE
> or <CODE
CLASS="OPTION"
>delete</CODE
> specify when this command is executed, on indexinf of a new document, 
on reindexing of a document or on delettion of a document.
If none of such option specified, the <CODE
CLASS="OPTION"
>add</CODE
> option is assumed by default.</P
><P
>Thus you can use ActionSQL commands to mind and collect the data on pages while indexing. 
For example, the following commands collect phone numbers (in Russian local notation) along with titles of pages where these phone numbers have been discovered:
<PRE
CLASS="PROGRAMLISTING"
>ActionSQL add body "\(([0-9]{3})\)[ ]*([0-9]{3})[- \.]*([0-9]{2})[- \.]*([0-9]{2})" "INSERT INTO phonedata(phone,title,id)VALUES('+7$1$2$3$4','$(title)',$(dp_id))"
ActionSQL update body "\(([0-9]{3})\)[ ]*([0-9]{3})[- \.]*([0-9]{2})[- \.]*([0-9]{2})" "UPDATE phonedata SET phone='+7$1$2$3$4',title='$(title)' WHERE id=$(dp_id)"
ActionSQL delete url "." "DELETE FROM phonedata WHERE id=$(dp_id)"</PRE
></P
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="dpsearch-indexcmd.en.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.en.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="dpsearch-syslog.en.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Other commands are used in <TT
CLASS="FILENAME"
>indexer.conf</TT
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="dpsearch-indexing.en.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Using syslog</TD
></TR
></TABLE
></DIV
><!--#include virtual="body-after.html"--></BODY
></HTML
>